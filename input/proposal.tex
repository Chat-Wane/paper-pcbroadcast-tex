
\section{Causal broadcast\\for large and dynamic systems}
\label{sec:proposal}

In this section, we introduce \CBROADCAST (stands for Preventive Causal
broadcast), a causal broadcast protocol that breaks the scalability barrier for
large and dynamic systems.  Our approach is preventive: instead of repairing
causal order violations or reordering received messages, it simply makes sure
that messages never arrive out of causal order. Processes can immediately
deliver messages upon receipt. This not only removes most of control information
piggybacked in broadcast messages, but also leads to constant delivery execution
time. Protocols and applications can finally afford causal broadcast in large
and dynamic systems without loss of efficiency.

\subsection{Model}

A distributed system comprise processes. Processes can communicate with each
other using messages. They may not have full knowledge of the membership, for
maintenance is too costly in large and dynamic systems. Instead, processes build
overlay networks with local partial view the size of which is generally much
smaller than the actual size of the
system~\cite{bertier-d2ht,jelasity2007gossip,jelasity2009tman}. Overlay networks
can be built on top of other overlay networks.  For the rest of this paper, we
will speak of distributed systems, overlay networks, or networks indifferently.

\begin{definition}[Overlay network]
  An overlay network $G$ is a pair $\langle P,\, E\rangle$ where $P$ is a set of
  processes, and $E$ is a set of links $E: P\times P$. An overlay network is
  static when $P$ and $E$ are immutable, otherwise it
  is dynamic.
\end{definition}

\begin{definition}[Process]
  A process runs a set of instructions sequentially and communicates
  with other processes using message passing. \\
  A process' neighborhood is the set of links departing from it. \\
  A process~A can send messages to another process~B in its neighborhood:
  $s_{AB}(m)$; receive a message from another process~C that has Process~A as
  neighbor:
  $r_{AC}(m)$. \\
  A process is faulty if it crashes, otherwise it is correct. We do not consider
  byzantine processes.
\end{definition}

% For the rest of the paper, we only consider networks without partitions.

\begin{definition}[Unpartitioned network]
  A network is unpartitioned if and only if for any pair of correct processes,
  there exist a path -- a link or a sequence of links -- of correct processes
  between them. We only consider unpartitioned overlay networks.
\end{definition}

Causal broadcast is a communication primitive that relies on reliable broadcast
to send messages to all processes in the system.

% Broadcasting constitutes a communication primitive that allows processes to send
% messages to all other processes in their system.

\begin{definition}[Uniform reliable broadcast]
  When a process~A broadcasts a message $b_A(m)$, each correct process~B in the
  network eventually receives it $r_B(m)$ and delivers it $d_B(m)$.
  Uniform reliable broadcast guarantees 3 properties: \\
  \textbf{Validity:} If a correct process broadcasts a message, then it
  eventually delivers it. \\
  \textbf{Uniform Agreement:} If a process -- correct or not -- delivers a
  message, then all correct processes eventually deliver it. \\
  \textbf{Uniform Integrity:} A process delivers a message at most once, and
  only if it was previously broadcast.
\end{definition}

\begin{algorithm}
  \input{./input/algoreliablebroadcast.tex}
  \caption{\label{algo:reliablebroadcast}R-broadcast at Process $p$.}
\end{algorithm}

Algorithm~\ref{algo:reliablebroadcast} shows the instructions of a uniform
reliable broadcast. It uses a structure that keeps track of received messages in
order to deliver them at most once.  Since processes may not have full
membership knowledge, processes must forward broadcast messages. Since the
network does not have partitions, processes either receive the message directly
from the broadcaster or transitively. Thus, all correct processes eventually
deliver all messages exactly once. R-broadcast ensures validity, uniform
agreement, and uniform integrity.

Causal broadcast is a reliable broadcast that also ensures a specific ordering
among message deliveries.  To define a delivery order among messages, we define
time in a logical sense using Lamport's definition~\cite{lamport1978time}.

\begin{definition}[Happen before~\cite{lamport1978time}]
  Happen before is a transitive, irreflexive, and antisymmetric relation
  $\rightarrow$ that defines a strict partial orders of events.  The sending of
  a message always precedes its receipt.
\end{definition}

%% To order messages broadcast from one process, we define FIFO order.

%% \begin{definition}[FIFO order]
%%   If a process broadcasts a first message then broadcasts a second message,
%%   processes deliver the first message before the second message.
%% \end{definition}

%% To order messages broadcast by different processes, we define local order.

%% \begin{definition}[Local order]
%%   If a process broadcasts a message after having delivered another message
%%   broadcast by another process, processes deliver the latter before the former.
%% \end{definition}

To order messages broadcast by every processes, we define causal order.

\begin{definition}[Causal order]
  The delivery order of messages follows the happen before relationships of the
  corresponding broadcasts. $\forall A,\,B,\,C,\,
  b_A(m) \rightarrow b_B(m') \implies d_C(m) \rightarrow d_C(m')$
\end{definition}

%% \begin{theorem}[\label{theo:causal}Causal order equivalence~\cite{hadzilacos1994modular}]
%%   The conjunction of FIFO order and local order is equivalent to causal order.
%% \end{theorem}

\begin{definition}[Causal broadcast]
  Causal broadcast is a uniform reliable broadcast ensuring causal order.
\end{definition}

\begin{theorem}[\label{theo:flooding}Constraint flooding in deterministic
  overlay networks is causal~\cite{friedman2004causal}]
  In static networks, a broadcast protocol is causal if it uses FIFO links,
  forwards all broadcast messages exactly once, and uses all its outgoing links.
\end{theorem}

From Theorem~\ref{theo:flooding}, reliable broadcast from
Algorithm~\ref{algo:reliablebroadcast} is causal if communication links employed
to communicate with neighbors in $Q$ are FIFO. This holds only for static
networks where $Q$ is immutable. In practice, processes can join, leave, add or
remove links to neighbors from $Q$ at any time.

\begin{lemma}[R-broadcast is causal in dynamic systems subject to
  removals\label{lem:removals}]
  R-broadcast using FIFO links is a causal broadcast in dynamic systems where
  processes can leave the system or links can be removed.
\end{lemma}

\begin{proof}
  Removing a process from the network and removing all the incoming and outgoing
  links of this process is equivalent. Since we assume that removals do not
  create network partitions\footnote{It may create partitions infringing the
    uniform agreement property. Network partitioning constitutes an orthogonal
    problem that we do not address in this paper.}, all correct processes
  eventually receive all broadcast messages. In addition, removing a link or a
  process does not reorder causally related messages. Hence, each process
  receives and delivers each broadcast message in causal order as in static
  systems.
\end{proof}

Link removals and process departures do not endanger broadcast properties.
However, Figure~\ref{fig:preventiveproblem} shows that adding links may lead to
causal order violations. The next section describes \CBROADCAST, a causal
broadcast that handles all dynamicity.

\subsection{Causal order in dynamic systems}

\begin{figure*}
  \begin{center}
    \subfloat[Part A][\label{fig:preventivesolveA}Process~A broadcasts $a$.]
    {\input{./input/figpreventivesolveA.tex}}
    \hspace{20pt}
    \subfloat[Part B][\label{fig:preventivesolveB}Process~A wants
    to add a link to Process~D. 
    It sends a ping message $\pi$ to Process~D using one of its FIFO links.]
    {\input{./input/figpreventivesolveB.tex}}
    \hspace{20pt}
    \subfloat[Part C][\label{fig:preventivesolveC}Process~A broadcasts $a'$.
    It does not send it through the new link but buffers it.]
    {\input{./input/figpreventivesolveC.tex}}
    \hspace{20pt}
    \subfloat[Part D][\label{fig:preventivesolveD}Process~D receives
    $\pi$ and replies to $A$.
    The reply $\rho$ can travel by any communication
    mean.]
    {\input{./input/figpreventivesolveD.tex}}
    \hspace{20pt}
    \subfloat[Part E][\label{fig:preventivesolveE}Process~A receives
    Process~D's reply. 
    The former safely empties its buffer to Process~D. 
    Using the new link cannot cause causal order violation anymore.]
    {\input{./input/figpreventivesolveE.tex}}
    \caption{\label{fig:preventivesolve}\CBROADCAST does not violate causal
      order in dynamic settings.}
  \end{center}
\end{figure*}


\CBROADCAST stands for Preventive Causal broadcast. It prevents causal order
violations by forbidding the usage of new links until proven safe. It
constitutes a powerful yet simple extension
of~\cite{friedman2004causal}. Table~\ref{table:comparison} shows that it
preserves both constant message overhead and constant delivery execution time in
dynamic settings.

Figure~\ref{fig:preventiveproblem} shows that adding links may infringe the
causal order property of causal broadcast.  New links may act as shortcut for
new messages: new messages that travel through new links may arrive before
preceding messages that took longer paths. To prevent this behavior, we define
the safety of a link. \CBROADCAST uses all and only safe links to disseminate
messages.

\begin{definition}[\label{def:safe}Safe link]
  A link from Process~A to Process~B is safe if and only if Process~B received
  or will receive all messages delivered by Process~A before receiving any
  message that Process~A will deliver:
  $safe_{AB} \equiv \forall m,\, m',\, d_A(m) \rightarrow s_{AB}(m') \implies
  r_B(m) \rightarrow r_{BA}(m')$
\end{definition}

Added links start unsafe. In Figure~\ref{fig:preventiveproblem}, Process~A uses
the link to broadcast $a'$ while it is unsafe: Process~B did not receive $a$
yet, and there was no guaranty that Process~B would receive $a$ before receiving
$a'$ from the new link. In this example, the worst happens and Process~B
receives then delivers $a'$ before $a$ which violates causal order.

The challenge is to make unsafe links safe using local knowledge only. A
straightforward mean for Process~A to achieve this consists in sending all its
delivered messages to Process~B using this unsafe link. This guarantees that any
message delivered by A will be received by B before A starts using the new --
now safe -- link for causal broadcast. However, this is costly both in local
space and generated traffic. Performing an anti-entropy round to extract missing
messages would also be overcostly in terms of generated traffic for it would
require sending the vector of received messages~\cite{demers1987epidemic}.
Instead, Process~A avoid sending most of messages by initiating a ping phase
to Process~B. %% while recording all its upcoming message deliveries in an array.

\begin{definition}[Ping phase]
  Ping phase starts when Process~A pings Process~B. Ping messages $\pi$ travel
  using safe links. When Process~B receives this ping, it replies to
  Process~A. Replies $\rho$ travel using any communication mean. Ping phase ends
  when Process~A receives the reply of Process~B.
\end{definition}

\begin{lemma}[\label{lemma:ping}Ping phases acknowledge broadcast receipts]
  A ping phase from Process~A to Process~B acknowledges the receipt by B of all
  messages delivered by Process~A before this ping phase:
  $\forall m,\, d_A(m) \rightarrow s_A(\pi_{AB}) \wedge r_A(\rho_{AB}) \implies
  r_B(m)$
\end{lemma}

\begin{proof}
  Suppose a process~A initiates a ping phase to a process B. Suppose series of
  messages delivered by Process~A. Process~A sent these messages exactly once
  using all its outgoing safe links. Processes that will receive these message
  either already forwarded them or will forward them in their receipt
  order. Since Process~A's ping travels using safe links after these messages,
  when Process~B receives the ping, it already received all messages delivered
  by Process~A. Process~A receives Process~B's reply after Process~B received
  the ping. Consequently, when Process~A receives Process~B's reply, Process~B
  received all messages delivered by Process~A before the start of this ping
  phase.
\end{proof}

Upon receipt of Process~B's reply, Process~A has the guaranty that Process~B
received all its delivered messages preceding the ping phase. This is not
sufficient, for ping phases take time. Messages delivered during ping phase by
Process~A may not be received by Process~B yet. To fill this gap, Process~A
sends to Process~B the messages it buffered during ping phase.

\begin{definition}[Buffering]
  Process~A records in a buffer $\mathcal{B}$ all its delivered messages during
  a ping phase to Process~B.
  $\forall m,\, s_A(\pi_{AB}) \rightarrow d_A(m) \wedge d_A(m)\rightarrow
  r_A(\rho_{AB}) \Leftrightarrow m \in \mathcal{B} $
\end{definition}


\begin{lemma}[Ping phase and buffering makes safe links]
  Process~A makes an unsafe link to Process~B safe by completing a ping phase to
  Process~B then finalizing it by sending all delivered messages buffered during
  ping phase using the new link.
\end{lemma}

\begin{proof}
  Suppose series of messages $m_1 \ldots m_i \ldots m_j$ delivered by a
  process~A. Suppose Process~A initiated a ping phase to a process B after
  delivering $m_i$. Suppose Process~A receives Process~B's reply after $m_j$.
  We must show that when Process~A delivers a message after $m_k$, Process~B
  received or will receive $m_1 \ldots m_j$ before. \\
  From Lemma~\ref{lemma:ping}, when Process~A receives Process~B's reply,
  Process~B received $m_1 \ldots m_i$. \\
  Since Process~A buffered all messages delivered since the beginning of the
  ping phase, the buffer contains $m_{i+1} \ldots m_j$ when the ping phase ends.
  Since links are FIFO, sending messages of this buffer using the new link
  guarantees that Process~B will receive them before receiving any $m_k$
  delivered after $m_j$. The link from Process~A to Process~B became safe.
  % Suppose a network of safe links without partitions. Suppose an unsafe link
  % from a process A to a process B. \\
  % We must show that if Process~B receives a message $m'$ from the new link,
  % there exist no messages $m$ delivered by Process~A that it did not receive. \\
  % Process~B starts receiving messages from the new link when Process~A sends its
  % buffer. Either $m'$ comes from this buffer or it is a message delivered by
  % Process~A afterward. \\
  % Process~A starts sending buffered messages once it received the reply to its
  % ping, hence, after Process~B received this ping. Since this ping travels via
  % safe FIFO links, and since the network does not have partitions, Process~B
  % eventually receives this ping after all messages delivered by Process~A when
  % it sent this ping. Consequently, there exist no messages $m$ that Process~B
  % did not receive before receiving the messages from the buffer. \\
  % Since Process~A buffered all delivered messages between the sending of the
  % ping and the receipt of the reply, there exist no messages $m$ that Process~B
  % did not receive before Process~A starts using the new link for
  % broadcast. \\
  % Afterward, Process~A sends all its delivered messages using this link.
\end{proof}

% Compared to reliable broadcast, Algorithm~\ref{algo:bufferbroadcast} adds a
% structure associating each new unsafe link with a buffer of
% messages.

\begin{lemma}[\CBROADCAST is causal in dynamic systems subject to
  additions\label{lem:additions}]
  In dynamic systems where processes can join or add links, broadcasting using
  all and only safe FIFO links ensures causal order. Without partition, the
  broadcast is causal.
\end{lemma}

\begin{proof}
  \CBROADCAST ensures \textbf{validity}, \textbf{uniform agreement}, and
  \textbf{uniform integrity},
  for it extends R-broadcast that ensures all 3 properties. \\
  We must show that \CBROADCAST ensures \textbf{causal order}:
  $\forall A,\,B,\,C,\, b_A(m) \rightarrow b_B(m')
  \implies d_C(m) \rightarrow d_C(m')$. \\
  $\forall A,\,B,\, b_A(m) \rightarrow b_B(m') \Leftrightarrow d_B(m)
  \rightarrow d_B(m') \Leftrightarrow d_B(m) \rightarrow s_B(m') \Leftrightarrow
  d_B(m) \rightarrow (\forall C\in Q, s_{BC}(m'))$.
  Since all links in $Q$ are safe links, $r_c(m) \rightarrow r_{CB}(m')$ (see
  Definition~\ref{def:safe}).  Since delivery order follows first receipt order,
  $d_C(m) \rightarrow d_C(m')$. This order on message delivery transitively
  reach all correct processes as long as the network remains unpartitioned.
\end{proof}



\begin{figure*}
  \begin{center}
    \subfloat[part A][\label{fig:bufferproblemA}Slow ping message $\pi$.]
    {\input{input/figbufferproblemA.tex}}
    \hspace{20pt}
    \subfloat[part B][\label{fig:bufferproblemB}Process~D crashes.]
    {\input{input/figbufferproblemB.tex}}
    \hspace{20pt}
    \subfloat[part C][\label{fig:bufferproblemC}Reply $\rho$ fails.]
    {\input{input/figbufferproblemC.tex}}
    \caption{\label{fig:bufferproblem}Buffers may grow unbounded due to network
      conditions.}
  \end{center}
\end{figure*}



\begin{algorithm}
  \input{./input/algobufferbroadcast.tex}
  \caption{\label{algo:bufferbroadcast}\CBROADCAST at Process $p$.}
\end{algorithm}


Algorithm~\ref{algo:bufferbroadcast} shows the small set of instructions that
implement safe links.  Figure~\ref{fig:preventivesolve} shows on an example how
it solves causal order violations. In Figure~\ref{fig:preventivesolveA},
Process~A broadcasts $a$.  In Figure~\ref{fig:preventivesolveB}, Process~A wants
to add a link to Process~D. It sends a ping message $\pi$ to Process~D (see
Line~\ref{line:sendlocked}) and awaits for the latter's reply.  We leave aside
the implementation of this send function (e.g. broadcast or routing).  While
awaiting, Process~A keeps its normal functioning and maintain a buffer of
messages associated with the unsafe link (see Line~\ref{line:bufferforward}). In
Figure~\ref{fig:preventivesolveC}, Process~A broadcasts another message $a'$. It
sends it normally to Process~B but does not send it to Process~D
directly. Instead, it buffers it. In Figure~\ref{fig:preventivesolveD},
Process~D receives Process~A's ping message $\pi$. Since links are FIFO, it
implicitly means that Process~D also received $a$. Process~D sends a reply
$\rho$ to Process~A (see Line~\ref{line:sendack}). $\rho$ can travel through any
communication mean. In Figure~\ref{fig:preventivesolveE}, Process~A receives
$\rho$. Consequently, Process~A knows that Process~D received and delivered at
least $a$ and all preceding messages. It empties the buffer of messages to
Process~D (see Line~\ref{line:emptybuffer}). Afterwards, the new link is
safe. Process~A uses the new link normally.



\begin{figure*}
  \begin{center}
    \subfloat[Part A][\label{fig:buffersolveA}
    Process~A wanted to add a link to Process~D after having
    broadcast $a$. Afterwards, it broadcast $a'$ and $a''$.]
    {\input{input/figbuffersolveA.tex}}
    \hspace{20pt}
    \subfloat[Part B][\label{fig:buffersolveB}
    Process~A receives, delivers, and forwards $x$. Since the buffer size would 
    exceed the maximal boundary, it resets the buffer with a new counter and
    sends a ping message with this counter. In the meantime, Process~D
    receives $\pi_1$ and sends the corresponding reply $\rho_1$.]
    {\input{input/figbuffersolveB.tex}}
    \hspace{20pt}
    \subfloat[Part C][\label{fig:buffersolveC}
    Process~A forwards $y$ and buffers it. It also
    receives $\rho_1$ but no buffers exist with this counter. Process~A 
    simply discards $\rho_1$.]
    {\input{input/figbuffersolveC.tex}}
    \hspace{20pt}
    \subfloat[Part D][\label{fig:buffersolveD}
    Process~D receives $\pi_2$ and sends the corresponding
    reply $\rho_2$.]
    {\input{input/figbuffersolveD.tex}}
    \hspace{20pt}
    \subfloat[Part E][\label{fig:buffersolveE}
    Process~A receives $\rho_2$. It empties the
    buffer with the corresponding counter. Now,  the direct link
    to Process~D is safe. Process~A uses it normally.]
    {\input{input/figbuffersolveE.tex}}
    \caption{\label{fig:buffersolve}Buffers become bounded. We allow only 2
      elements in each buffer.}
  \end{center}
\end{figure*}

%% \begin{proof}
%%   To prove that \CBROADCAST is a causal broadcast, we must show that it ensures
%%   validity, uniform agreement, uniform integrity, and causal order. \\
%%   \textbf{Validity, uniform agreement, uniform integrity:} \CBROADCAST extends
%%   R-broadcast. Since R-broadcast ensures validity, uniform agreement, and
%%   uniform
%%   integrity, \CBROADCAST ensures all 3 properties. \\
%%   \textbf{Causal order:} From Theorem~\ref{theo:causal}, we must show
%%   that \CBROADCAST ensures both FIFO order and local order. \\
%%   \textbf{FIFO order:} Suppose a process A broadcasts $m$ before $m'$. Consider
%%   that a correct process B delivers $m'$. We must show that Process~B
%%   delivers $m$ before $m'$. \\
%%   Processes use added links only when they are safe. Thus, when Process~A
%%   broadcasts $m'$, direct neighbors already received or are guaranteed to
%%   receive $m$ beforehand. Since delivery order follows the receipt order, direct
%%   neighbors deliver $m$ before $m'$. They forward $m$ and $m'$ in this
%%   order. The rest of processes receive in this order. Process~B receives $m$
%%   before $m'$ either directly or transitively. Consequently, Process~B delivers
%%   $m$ before $m'$. \\
%%   \textbf{Local order:} Since broadcast and forward have identical instructions,
%%   the origin of broadcast messages does not matter. The proof is identical to
%%   that of FIFO order. \\
%% \end{proof}

\begin{theorem}[\CBROADCAST is a causal broadcast]
  \CBROADCAST is a causal broadcast in both static and dynamic network settings.
\end{theorem}

\begin{proof}
  For static networks, it comes from~\cite{friedman2004causal}. For dynamic
  networks, it comes from Lemmas~\ref{lem:removals}~and~\ref{lem:additions}.
\end{proof}

\subsection{Bounding space consumption}

Algorithm~\ref{algo:bufferbroadcast} ensures causal delivery of messages even in
dynamic network settings. Compared to the original causal broadcast for static
networks~\cite{friedman2004causal}, it uses an additional local structure:
buffers of messages. It associates a buffer to each new unsafe links. We assumed
that the size of these buffer stays small in general, for it depends on the time
taken by the ping phase which is assumed short. However, network conditions may
invalidate this assumption. Figure~\ref{fig:bufferproblem} depicts scenarios
where buffers grow out of acceptable boundaries. In
Figure~\ref{fig:bufferproblemA}, the issue comes from high transmission delays
from Process~A to Process~B, and from Process~B to Process~D compared to the
number of messages to broadcast and forward. The ping message $\pi$ did not
reach Process~D yet that the buffer contains a lot of messages. In
Figure~\ref{fig:bufferproblemB}, the issue comes from the departure of
Process~D. Depending on network settings, Process~A may not be able to detect
Process~D's departure. The former will never receive the awaited reply and the
buffer will grow forever. In Figure~\ref{fig:bufferproblemC}, the reply $\rho$
itself fails to reach Process~A. For the recall, this message can travel to
Process~A by any communication mean, including unreliable ones. If this fails,
Process~A's buffer to Process~D will grow
forever. %as long as Process~A receives or broadcasts
%messages.

\begin{algorithm}
  \input{input/algoboundingbuffer.tex}
  \caption{\label{algo:boundingbuffer}Bounding the size of buffers and handling
    network failures.}
\end{algorithm}

Algorithm~\ref{algo:boundingbuffer} solves the unbounded growth issue of
buffers. It solves the issue from the buffer owner's
perspective. Figure~\ref{fig:buffersolve} shows how this algorithm bounds the
size of buffers. In Figure~\ref{fig:buffersolveA}, Process~A broadcast $a$; then
wanted to add a link to Process~D so it sent a ping message; then broadcast $a'$
and $a''$ so it buffered them. We see that the ping message $\pi_1$ carries a
counter. The new buffer is identified by the same counter. In
Figure~\ref{fig:buffersolveB}, Process~A receives, delivers, and forwards the
message $x$. Each message delivery increases the size of current buffers. The
algorithm checks if the size of the buffer exceeds the configured bound (see
Line~\ref{line:maxsize}). Adding $x$ to the buffer would exceed the bound of $2$
elements. This is the first ping phase failure. Process~A simply restarts the
ping phase: it resets the buffer and sends another ping message $\pi_2$ (see
Line~\ref{line:reset}). The counter of the reset buffer is the one of the new
ping message. In the meantime, Process~D receives $\pi_1$ and sends the
corresponding reply $\rho_1$. In Figure~\ref{fig:buffersolveC}, Process~A
receives a broadcast message $y$. It delivers it, checks if the buffer can admit
it, adds the message to the buffer, and forwards it. Process~A also receives the
first reply $\rho_1$ but discards it, for no buffers have such counter. In
Figure~\ref{fig:buffersolveD}, Process~D receives $\pi_2$ and sends the
corresponding reply $\rho_2$ to Process~A. In Figure~\ref{fig:buffersolveE},
Process~A receives $\rho_2$. Since the corresponding buffer exists, it empties
it. The new link is now safe to use for causal broadcast.

While it solves the issue of unbounded buffers, it also brings another
issue. For instance, if the maximal size of buffers is too small, it could stuck
the protocol in a loop of retries. We address this issue by bounding the number
of retries. However, it means that the ping phase could fail
entirely. Causal broadcast must not employ the new link. In extreme cases, it
could cause partitions in the causal broadcast overlay network. It would violate
the uniform agreement property of causal broadcast. Thus, we assume a
sufficiently large maximal bound. It never creates partitions, for most links
become safe, and the failing ones are replaced over time thanks to
network dynamicity.

Other orthogonal improvements are possible. For instance, causal broadcast could
use reliable communication means to acknowledge the receipt of the ping
message. The time taken between the sending and the receipt of the
reply would increase when failures occur. However, it would take less
time than resetting the buffering phase.

\subsection{Complexity}
\label{subsec:complexity}

We review and discuss about the complexity of \CBROADCAST. We distinguish the
complexity brought by 
\begin{inparaenum}[(i)]
\item the overlay network,
\item reliable broadcast,
\item and causal ordering.
\end{inparaenum}

\noindent \textbf{Overlay network.} Processes cannot afford the upkeep of full
membership in large and dynamic systems. Instead, each process builds a partial
view the size of which is considerably smaller than the actual network size.  To
maintain these partial views, each process runs a peer-sampling
protocol~\cite{bertier-d2ht,jelasity2007gossip,jelasity2009tman}.  Some
peer-sampling protocols provides partial views the size of which scales
logarithmically with the actual network size~\cite{nedelec2017adaptive}.  The
number of messages forwarded by each process for each broadcast remains small,
for this number is equal to their view size: $O(Q)$ where $Q$ is the size of the
partial view.


\noindent \textbf{Reliable broadcast.} Gossiping constitutes an efficient mean
to disseminate messages to all
processes~\cite{demers1987epidemic},~\cite{birman1999bimodal}.
Algorithm~\ref{algo:reliablebroadcast} shows that it relies on a local structure
to guarantee that messages are delivered exactly once. This structure grows
linearly with the number of processes in the network: $O(N)$. In addition, each
message piggybacks a pair $\langle process,\, counter \rangle$ that identifies
it: $O(1)$. Checking if a message is a duplicate takes constant time: $O(1)$.

\noindent \textbf{Causal ordering.} Causal ordering primarily uses FIFO links to
broadcast messages which implies a constant size overhead on messages
$O(1)$. Most space complexity is hidden by FIFO links including that of buffered
messages ensuring safety.
%Its local space complexity is $O(W + B)$ where $W$ is the number of messages
%awaiting on FIFO links, and $B$ is the size of the structure required to ensure
%link safety.
\CBROADCAST maintains one buffer per unsafe link during its ping phase.  We
assume that this time is short so the number of buffered messages stays
small. As shown in Section~\ref{sec:proposal}, network conditions can make this
assumption false. Algorithm~\ref{algo:boundingbuffer} allows to bound the size
of each buffer and handle network failures.

\noindent \textbf{Overall.}  Generated traffic remains the most important
criterion for scalability. The traffic generated by \CBROADCAST for each process
and for each broadcast only depends on the size of messages and the overlay
network chosen to broadcast messages. The size of messages is an irreducible
variable; and many protocols designed to build overlay networks achieve high
scalability in terms of network size and
dynamicity~\cite{bertier-d2ht,jelasity2007gossip,jelasity2009tman},~\cite{nedelec2017adaptive,voulgaris2005cyclon}.
Consequently, \CBROADCAST achieve high scalability in both these terms
too. \CBROADCAST is efficient, for the upper bound on the complexity of delivery
execution time does not depend on any factor.

However, to ensure causal order, \CBROADCAST may not use all outgoing links in
dynamic settings, for some may be temporarily unsafe. This negatively impacts
the overlay network properties. The next section shows an experiment that
highlights the influence of \CBROADCAST's way to ensure causal order on the
underlying overlay network. In particular, it shows that the number of hops
required by a broadcast message to reach all processes increases when delays on
transmission increase.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../paper"
%%% End:
