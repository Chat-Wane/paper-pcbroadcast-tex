
\section{Causal broadcast for large and dynamic networks}
\label{sec:proposal}

In this section, we introduce \CBROADCAST (stands for Preventive Causal
broadcast), a causal broadcast protocol that breaks scalability barriers for
large and dynamic networks.
% It does not overload
% messages with any control information. 
To provide causal order, most
state-of-the-art~\cite{almeida2008interval,birman1987reliable,fidge1988timestamps,hadzilacos1993fault,mattern1989virtual,mostefaoui2017probabilistic,singhal1992efficient}
approaches are reactive, for they check if message deliveries should be delayed
to avoid causality violations. Our approach is preventive, for messages are
immediately delivered on receipt without risk of causality violations. This
difference not only removes most of control information piggybacked in broadcast
messages, but also leads to constant delivery time. Protocols and applications
can finally afford causal broadcast in large and dynamic networks without loss
of efficiency.

% This section states  the definitions. It describes our algorithm. It proves that
% it handles both static and dynamic networks. It analyses its complexity.

\subsection{Model}

% Definitions and theorems come from~\cite{hadzilacos1994modular}.
A network comprise processes. Processes can communicate with part of the network
via messages. They may not have full knowledge of network membership, for
maintenance costs become too expansive in large and dynamic networks. Instead,
processes build overlay networks with local partial view the size of which is
generally much smaller than the actual network size.

\begin{definition}[Overlay network]
  Just as a network, an overlay network $N$ comprises a set of processes
  $P$. Each Process runs a
  set of instructions sequentially. \\
  An overlay network $N$ also comprises a set of links $E: P \times P$. $p$'s
  neighborhood $Q$ is the set of links departing from $p$. Processes can
  communicate with their neighbors using messages. \\
  Processes are faulty if they crash, otherwise they are correct. The set of
  correct processes is $C$. There are no byzantine processes.
\end{definition}

For the rest of this paper, we will speak of networks and overlay networks
indifferently.

\begin{definition}[Static and dynamic networks]
  A network is static if both its set of processes and its set of edges are
  immutable. Otherwise, the network is dynamic.
\end{definition}

For the rest of the paper, we only consider networks without partitions.

\begin{definition}[Network partition]
  A network has partitions if there exist two correct processes without any path
  between them, i.e., without a link or a sequence of links comprising correct
  processes only.
\end{definition}

%\TODO{Replace ``network'' by  ``distributed system'' ?}

Processes communicate by sending messages to other processes. They can send
messages to specific processes or all of them.

\begin{definition}[Uniform reliable broadcast]
  A process can broadcast a message, receive a message, and deliver a message.
  When a process broadcasts a message to all processes of the network, correct
  processes eventually receive it. 
  Uniform reliable broadcast guarantees 3 properties: \\
  \textbf{Validity:} If a correct process broadcasts a message, then it
  eventually delivers it. \\
  \textbf{Uniform Agreement:} If a process -- correct or not -- delivers a
  message, then all correct processes eventually deliver it. \\
  \textbf{Uniform Integrity:} A process delivers a message at most once, and
  only if it was previously broadcast.
\end{definition}

\begin{algorithm}[h]
  \input{./input/algoreliablebroadcast.tex}
  \caption{\label{algo:reliablebroadcast}R-broadcast at Process $p$.}
\end{algorithm}

Algorithm~\ref{algo:reliablebroadcast} shows the instructions of a uniform
reliable broadcast. It uses a structure that keeps track of received messages in
order to deliver them at most once. 
%It uses a peer-sampling protocol that
%provides neighbors to communicate with, i.e., a set of links. 
%%Assuming a network without partitions meaning that there exists at least one
%path from any process to any correct process, then all correct processes
%eventually receive all messages at least once:
Since processes may not have full membership knowledge, processes must forward
broadcast messages. Since the network does not have partitions, processes either
receive the message directly from the broadcaster or transitively. Thus, all
correct processes eventually deliver all messages exactly once. This algorithm
ensures validity, uniform agreement, and uniform integrity.

At this point, processes receive and deliver each message exactly once. However,
R-broadcast delivers messages in any order.  In addition to reliably conveying
messages to all correct processes, broadcast protocols can ensure that messages
are delivered in a specific order.

To define a delivery order among messages, we define time in a logical sense
using Lamport's definition~\cite{lamport1978time}.

\begin{definition}[Happen before~\cite{lamport1978time}]
  Happen before is a transitive, irreflexive, and antisymmetric relation that
  defines a strict partial orders of events.  The sending of a message always
  precedes its receipt.
\end{definition}

To order messages broadcast from one process, we define FIFO order.

\begin{definition}[FIFO order]
  If a process broadcasts two messages, processes deliver the first before the
  second.
\end{definition}

To order messages broadcast by different processes, we define local order.

\begin{definition}[Local order]
  If a process broadcasts a message after having delivered another message
  broadcast by another process, processes deliver the latter before the former.
\end{definition}

To order messages broadcast by every processes, we define causal order.

\begin{definition}[Causal order]
  The delivery order of messages follows the happen before relationships of the
  corresponding broadcasts.
\end{definition}

\begin{theorem}[\label{theo:causal}Causal order equivalence~\cite{hadzilacos1994modular}]
  The conjunction of FIFO order and local order is equivalent to causal order.
\end{theorem}

\begin{definition}[Causal broadcast]
  Causal broadcast is a uniform reliable broadcast ensuring causal order.
\end{definition}

\begin{theorem}[\label{theo:flooding}Constraint flooding in deterministic
  overlay networks is causal~\cite{friedman2004causal}]
  In static networks, a broadcast protocol is causal if it uses FIFO links,
  forwards all broadcast messages exactly once, and uses all its outgoing links.
\end{theorem}

From Theorem~\ref{theo:flooding}, reliable broadcast from
Algorithm~\ref{algo:reliablebroadcast} is causal if communication links employed
to communicate with processes of $Q$ are FIFO. This holds only for static
networks where $Q$ is immutable. In practice, processes add and removes elements
from $Q$ at any time. Next section describes a preventive causal broadcast that
handles such dynamicity.


\subsection{Operation}

\begin{algorithm}[h]
  \input{./input/algobufferbroadcast.tex}
  \caption{\label{algo:bufferbroadcast}\CBROADCAST at Process $p$.}
\end{algorithm}

\begin{figure*}
  \begin{center}
    \subfloat[Part A][\label{fig:preventivesolveA}Process~A broadcasts $a$.]
    {\input{./input/figpreventivesolveA.tex}}
    \hspace{20pt}
    \subfloat[Part B][\label{fig:preventivesolveB}Process~A wants
    to add a link to Process~D. 
    It sends a locked message $\ell$ to Process~D using one of its FIFO links.]
    {\input{./input/figpreventivesolveB.tex}}
    \hspace{20pt}
    \subfloat[Part C][\label{fig:preventivesolveC}Process~A broadcasts $a'$.
    It does not send it through the new link but buffers it.]
    {\input{./input/figpreventivesolveC.tex}}
    \hspace{20pt}
    \subfloat[Part D][\label{fig:preventivesolveD}Process~D receives
    $\ell$ and acknowledges it to $A$.
    The acknowledgment message $\alpha$ can travel by any communication
    mean.]
    {\input{./input/figpreventivesolveD.tex}}
    \hspace{20pt}
    \subfloat[Part E][\label{fig:preventivesolveE}Process~A receives
    Process~D's acknowledgment. 
    The former safely empties its buffer to Process~D. 
    Using the new link cannot cause causal order violation anymore.]
    {\input{./input/figpreventivesolveE.tex}}
    \caption{\label{fig:preventivesolve}Preventive causal broadcast does not violate
      causal order in dynamic networks anymore.}
  \end{center}
\end{figure*}

Algorithm~\ref{algo:bufferbroadcast} shows the instructions of \CBROADCAST. Its
two operations broadcast and deliver rely on reliable broadcast (see
Algorithm~\ref{algo:reliablebroadcast}). In fact, without additions nor removals
of links, our protocol only executes instructions of reliable broadcast (see
Line~\ref{line:rbroadcast},~\ref{line:rdeliver}).

\begin{theorem}[\CBROADCAST is causal in static networks\label{theo:static}]
  \CBROADCAST is a causal broadcast in static networks.
\end{theorem}

\begin{proof}
  In static networks, \CBROADCAST only executes the instructions of reliable
  broadcast. Reliable broadcast along with FIFO links ensures causal broadcast.
  The proof can be found in Paper~\cite{friedman2004causal}.
\end{proof}

The removal of links and the departure of processes are not an issue, for it
does not reorder messages traveling through the links\footnote{It may create
  partitions infringing the uniform agreement property. Network partitioning
  constitutes an orthogonal problem that we do not address in this
  paper.}. Algorithm~\ref{algo:bufferbroadcast} does not provide specific
instructions for such cases.
% However, it may create partitions. It is an orthogonal problem

\begin{lemma}[\CBROADCAST is causal in dynamic networks subject to
  removals\label{lem:removals}]
  \CBROADCAST is a causal broadcast in dynamic networks where processes can
  leave the network or links can be removed.
\end{lemma}

\begin{proof}
  Removing a process from the network and removing all the incoming and outgoing
  links of this process is equivalent. We assume that removals do not create
  network partitions.  Removing a link does not change the delivery order of
  causally related messages. Identically to the proof of
  Theorem~\ref{theo:static}, our causal broadcast only executes instructions of
  reliable broadcast in such cases. The proof can be found in
  Paper~\cite{friedman2004causal}.
\end{proof}

Our causal broadcast becomes more sophisticated when the process adds links.
Figure~\ref{fig:preventiveproblem} shows the issue with link additions.  New
links may act as shortcut for messages. First messages that travel through new
links may arrive before preceding messages that took longer paths. New links
create additional diffusion paths that potentially disorder messages.  Solving
this issue requires that even new links convey all messages in the right
order. Sending all broadcast messages since the beginning would be too
costly. Instead, a process $p$ creating a link to a process $q$ needs to know
the messages received by $q$ to send potentially missing messages in the right
order using this link. While obtaining $q$'s acknowledgment would be costly in
general settings, using already created FIFO links keeps it cheap. Once missing
messages have been sent through this new link, $p$ starts to use it
normally. New links do not create diffusion paths that could break causal order.

Compared to reliable broadcast, Algorithm~\ref{algo:bufferbroadcast} adds a
structure associating each new link with a buffer of
messages. Figure~\ref{fig:preventivesolve} shows how it solves causal order
violations. In Figure~\ref{fig:preventivesolveA}, Process~A broadcasts $a$.  In
Figure~\ref{fig:preventivesolveB}, it wants to add a link to Process~D. It sends
a locked message $\ell$ to process~D (see Line~\ref{line:sendlocked}) and awaits
for the latter's acknowledgment.  We leave aside the implementation of this send
function (e.g. broadcast or routing). Although, using already established FIFO
links constitutes a cheap way to achieve it. While awaiting, Process~A keeps its
normal functioning and maintain a buffer of messages associated with the new
link (see Line~\ref{line:bufferbroadcast},~\ref{line:bufferforward}). In
Figure~\ref{fig:preventivesolveC}, Process~A broadcasts another message $a'$. It
sends it normally to Process~B but does not send it to Process~D
directly. Instead, it buffers it. In Figure~\ref{fig:preventivesolveD},
Process~D receives Process~A's locked message $\ell$. Since links are FIFO, it
implicitly means that Process~D also received $a$. Process~D sends an
acknowledgment $\alpha$ to Process~A (see Line~\ref{line:sendack}). $\alpha$ can
travel through any communication mean. In Figure~\ref{fig:preventivesolveE},
Process~A receives $\alpha$. Consequently, Process~A knows that Process~D
received and delivered at least $a$ and all preceding messages. It empties the
buffer of messages to Process~D (see Line~\ref{line:emptybuffer}). Afterwards,
Process~A uses the new link normally.

\begin{figure*}
  \begin{center}
    \subfloat[part A][\label{fig:bufferproblemA}Slow locked message $\ell$.]
    {\input{input/figbufferproblemA.tex}}
    \hspace{20pt}
    \subfloat[part B][\label{fig:bufferproblemB}Process~D crashes.]
    {\input{input/figbufferproblemB.tex}}
    \hspace{20pt}
    \subfloat[part C][\label{fig:bufferproblemC}Acknowledgment $\alpha$ fails.]
    {\input{input/figbufferproblemC.tex}}
    \caption{\label{fig:bufferproblem}Buffers may grow unbounded due to network
      conditions.}
  \end{center}
\end{figure*}



The acknowledgment phase ensures that Process~D received all messages preceding
$a$ and $a$ itself. The buffering phase ensures that Process~D receives all
messages between the sending of the locked message $\ell$ and the receipt of
Process~D's acknowledgment $\alpha$. Afterwards, Process~D will receive
Process~A's broadcast or forwarded messages from this new direct link or
transitively through Process~B.

\begin{lemma}[\CBROADCAST is causal in dynamic networks subject to
  additions\label{lem:additions}]
  \CBROADCAST is a causal broadcast in dynamic networks where processes can join
  the network or links can be added.
\end{lemma}

\begin{proof}
  To prove that \CBROADCAST is a causal broadcast, we must show that it ensures
  validity, uniform agreement, uniform integrity, and causal order -- that is
  FIFO order and local order. \\
  \textbf{Validity, uniform agreement, uniform integrity:} \CBROADCAST is an
  R-broadcast. \\
  \textbf{FIFO:} Suppose a process $p$ broadcasts $m$ before $m'$. Consider that
  a correct process $q$ delivers $m'$. We must show that $q$ delivers $m$ before
  $m'$.  Since adding a FIFO link from a Process $r$ to any other Process $s$ is
  like adding potential FIFO paths from $p$ to $q$, we summarize this as a link
  from $p$ to $q$ with arbitrary settings but still FIFO.  \TODO{Should this be
    a proof?  Maybe a proof of equivalent model if kept}. \\
  Since Process $q$ delivers $m'$ it either received $m'$ from already well
  established links, or from the new one. In the former case, the proof is
  identical to that of Theorem~\ref{theo:static}. In the latter case, Process
  $q$ delivers $m'$ means that Process $p$ broadcasts $m$ then $m'$ either
  \begin{inparaenum}[(i)]
  \item \label{case:one} $m'$ during buffering and $m$ before buffering;
  \item \label{case:two} $m'$ during buffering and $m$ during buffering;
  \item \label{case:three} $m'$ after acknowledgment and $m$ before buffering;
  \item \label{case:four} $m'$ after acknowledgment and $m$ during buffering;
  \item \label{case:five} $m'$ after acknowledgment and $m$ after acknowledgment.
  \end{inparaenum}
  We must show that either 
  \begin{inparaenum}[(1)]
  \item \label{show:one} Process $q$ already received $m$ from another link
    before receiving $m'$ from the new link,
  \item \label{show:two} or that this new link conveyed $m$ before $m'$.
  \end{inparaenum}

  \begin{itemize}
  \item [(\ref{case:one})] Process $p$ put $m'$ in the buffer. Process $p$
    empties the buffer containing $m'$ after $p$ received an acknowledgment
    meaning that at least $m$ has been received at $q$. This
    shows~(\ref{show:one}).
  \item [(\ref{case:two})] Process $p$ put $m$ then $m'$ in the buffer. When the
    acknowledgment is received, it sends $m$ then $m'$ to Process $q$. This
    shows~(\ref{show:two}).
  \item [(\ref{case:three})] Identical to case~(\ref{case:one}) without the need
    of buffering.
  \item [(\ref{case:four})] Since Process $p$ empties the buffer containing $m$
    when it receives the acknowledgment, and since Process $p$ broadcasts $m'$
    afterwards using the new link, it shows~(\ref{show:two}).
  \item [(\ref{case:five})] It directly shows~(\ref{show:two}).
  \end{itemize}
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  % If Process $p$ broadcasts $m$ before the link addition, Process $p$ either
  % broadcasts $m'$ during buffering phase or after acknowledgment: 
  % \begin{itemize}
  % \item In the former case, since the receipt of $m$ precedes the creation of the
  %   acknowledgement, when $p$ receives the acknowledgement, it empties the buffer
  %   containing $m'$ to $q$. Hence, from any path, Process $q$ receives and
  %   delivers $m$ before $m'$.
  % \item In the later case, the acknowledgement confirms that $q$ received
  %   $m$. Afterwards, when $p$ broadcasts $m'$ it travels, among others, the newly
  %   created link, and eventually arrives to $q$.
  % \end{itemize}
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  % If Process $p$ broadcasts $m$ during buffering phase, Process $p$ either
  % broadcasts $m'$ during buffering phase or after acknowledgement.
  % \begin{itemize}
  % \item In the former case, $p$ puts $m$ in the buffer before $m'$. When $q$
  %   receives $m'$, either it already received $m$ from another FIFO channel or
  %   it already received $m$ from the emptied buffer that contained $m$ before
  %   $m'$.
  % \item In the later case, When $q$ receives $m'$, either it received $m$ from
  %   FIFO channel or the buffer that empties after acknowledgment.
  % \end{itemize}
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  % If Process $p$ broadcasts $m$ after acknowledgement, Process $p$ broadcasts
  % $m'$ after acknowledgement. It corresponds to the static network (see proof of
  % Theorem~\ref{theo:static}).
  % In any case, process $q$ delivers $m$ before $m'$. \\
  \textbf{Local:} Since broadcast and forward have identical instructions, the
  proof is identical to that of FIFO order. \\
  % Suppose a process $p$ delivers $m$ before broadcasting $m'$. Consider a
  % correct process $q$ that delivers $m'$. We must show that $q$ delivers $m$
  % before $m'$. Just as the proof for Theorem~\ref{theo:static}, the difference
  % in our Algorithm compared to FIFO order demonstration is that Process $q$ may
  % have already received -- or is the origin of the broadcast of --
  % $m$. \TODO{Not over}  
  \textbf{Causal:} From Theorem~\ref{theo:causal}, since \CBROADCAST ensures
  both FIFO order and local order, it ensures causal order.
\end{proof}

\begin{theorem}[\CBROADCAST is a causal broadcast]
  \CBROADCAST is a causal broadcast in both static and dynamic network settings.
\end{theorem}

\begin{proof}
  For static networks, it comes from Theorem~\ref{theo:static}. For dynamic
  networks, it comes from Lemmas~\ref{lem:removals}~and~\ref{lem:additions}.
\end{proof}

Algorithm~\ref{algo:bufferbroadcast} ensures causal delivery of messages even
with dynamic network settings. Compared to preventive causal broadcast for
static networks, it uses an additional local structure: buffers of messages. It
associates a buffer to each new links not yet acknowledged. We assumed that the
size of these buffer stays small in general, for it depends of the time between
the sending of locked message and the receipt of its acknowledgment which is
assumed short. However, network conditions may invalidate this
assumption. Figure~\ref{fig:bufferproblem} depicts scenarios where buffers grow
out of acceptable boundaries. In Figure~\ref{fig:bufferproblemA}, the issue
comes from high transmission delays from Process~A to Process~B, and from
Process~B to Process~D compared to the number of messages to broadcast and
forward. The locked message $\ell$ did not reach Process~D yet that the buffer
contains a lot of messages. In Figure~\ref{fig:bufferproblemB}, the issue comes
from the departure of Process~D. Depending on network settings, Process~A may
not be able to detect Process~D's departure. The former will never receive the
awaited acknowledgment and the buffer will grow forever. In
Figure~\ref{fig:bufferproblemC}, the acknowledgment $\alpha$ itself fails to
reach Process~A. For the recall, this message can travel to Process~A by any
communication mean, including unreliable ones. If this fails, Process~A's buffer
to Process~D will grow forever. %as long as Process~A receives or broadcasts
%messages.

\begin{algorithm}
  \input{input/algoboundingbuffer.tex}
  \caption{\label{algo:boundingbuffer}Bounding the size of buffers and handling
    network failures.}
\end{algorithm}

\begin{figure*}
  \begin{center}
    \subfloat[Part A][\label{fig:buffersolveA}
    Process~A wanted to add a link to Process~D after having
    broadcast $a$. Afterwards, it broadcast $a'$ and $a''$.]
    {\input{input/figbuffersolveA.tex}}
    \hspace{20pt}
    \subfloat[Part B][\label{fig:buffersolveB}
    Process~A broadcasts $a'''$. Since the buffer size would 
    exceed the maximal boundary, it resets the buffer with a new counter and
    sends a locked message with this counter. In the meantime, Process~D
    receives $\ell_1$ and sends the corresponding acknowledgment $\alpha_1$.]
    {\input{input/figbuffersolveB.tex}}
    \hspace{20pt}
    \subfloat[Part C][\label{fig:buffersolveC}
    Process~A forwards $y$ and buffers it. It also
    receives $\alpha_1$ but no buffer exists with this counter. Process~A 
    simply discards $\alpha_1$.]
    {\input{input/figbuffersolveC.tex}}
    \hspace{20pt}
    \subfloat[Part D][\label{fig:buffersolveD}
    Process~D receives $\ell_2$ and sends the corresponding
    acknowledgment $\alpha_2$.]
    {\input{input/figbuffersolveD.tex}}
    \hspace{20pt}
    \subfloat[Part E][\label{fig:buffersolveE}
    Process~A receives $\alpha_2$. It empties the
    buffer with the corresponding counter. Now,  the direct link
    to Process~D is safe. Process~A uses it normally.]
    {\input{input/figbuffersolveE.tex}}
    \caption{\label{fig:buffersolve}Buffers become bounded. We allow only 2
      elements in each buffer.}
  \end{center}
\end{figure*}

Algorithm~\ref{algo:boundingbuffer} solves the unbounded growth issue of
buffers. It solves the issue from the buffer owner's
perspective. Figure~\ref{fig:buffersolve} shows how this algorithm bounds the
size of buffers. In Figure~\ref{fig:buffersolveA}, Process~A broadcast $a$; then
wanted to add a link to Process~D so it sent a locked message; then broadcast
$a'$ and $a''$ so it buffered them. We see that the locked message $\ell_1$
carries a counter. The new buffer is identified by the same counter. In
Figure~\ref{fig:buffersolveB}, Process~A broadcasts another message $a'''$. Each
message delivery increases the size of current buffers. The algorithm checks if
the size of the buffer exceeds the configured bound (see
Line~\ref{line:maxsize}). Adding $a'''$ to the buffer would exceed the bound of
$2$ elements. It is first failure, so Process~A simply restarts the
acknowledgment phase: it resets the buffer and sends another locked message
$\ell_2$ (see Line~\ref{line:reset}). The counter of the reset buffer is the one
of the new locked message. In the meantime, Process~D receives $\ell_1$ and
sends the corresponding acknowledgment $\alpha_1$. In
Figure~\ref{fig:buffersolveC}, Process~A receives a broadcast message $y$. It
delivers it, checks if the buffer can admit it, adds the message to the buffer,
and forwards it. Process~A also receives the first acknowledgment $\alpha_1$ but
discards it, for no buffer has such counter. In Figure~\ref{fig:buffersolveD},
Process~D receives $\ell_2$ and sends the corresponding acknowledgment
$\alpha_2$ to Process~A. In Figure~\ref{fig:buffersolveE}, Process~A receives
$\alpha_2$. Since the corresponding buffer exists, it empties it. The new link
is now safe to use for causal broadcast.

While it solves the issue of unbounded buffers, it also brings another
issue. For instance, if the maximal size of buffers is too small, it could stuck
the protocol in a loop of retries. We address this issue by bounding the number
of retries. However, it means that the acknowledgment phase could fail
entirely. Causal broadcast must not employ the new link. In extreme cases, it
could cause partitions in the causal broadcast overlay network. It would violate
the uniform agreement property of causal broadcast. Thus, we assume a
sufficiently large maximal bound. It never creates partitions, for most links
are safely acknowledged, and the failing ones are replaced over time thanks to
network dynamicity.

Other orthogonal improvements are possible. For instance, causal broadcast could
use reliable communication means to acknowledge the receipt of the locked
message. The time taken between the sending and the receipt of the
acknowledgment would increase when failures occur. However, it would take less
time than resetting the buffering phase.

\subsection{Complexity}
\label{subsec:complexity}

We review and discuss about the complexity of \CBROADCAST. We distinguish the
complexity brought by
\begin{inparaenum}[(i)]
\item causal ordering,
\item reliable broadcast,
\item and the overlay network.
\end{inparaenum}

\PAR{Causal ordering.}{Regarding message overhead, broadcast messages convey two 
  types of control information: data to ensure FIFO order links, and
  data to globally identify the message. Thus, 
  message overhead is constant. 
  % Regarding traffic, broadcast messages do not need to convey any control
  % information. 
  Regarding number of messages, processes must send each message to all their
  neighborhood exactly once. It creates as many copies as neighbors. This number
  of copies may constitute an issue when the size of messages is large. To solve
  this issue, processes can send identifiers instead of large messages then send
  these messages on demand.  It introduces additional delays in communications
  but greatly reduces generated traffic~\cite{frey:hal-01479885}.  Regarding
  local space consumption, our protocol maintains one buffer per link during its
  acknowledgment time. We assume that this time is short so the number of
  buffered messages stays small. As shown in Section~\ref{sec:proposal}, network
  conditions can make this assumption false. Algorithm~\ref{algo:boundingbuffer}
  allows to bound the size of each buffer and handle network failures.}

% While Algorithm~\ref{algo:bufferbroadcast} shows no buffer management which
% means that they can grow unbounded, we can easily bound them. For instance,
% above a threshold we clear the buffer and send another locked message, or we
% remove the link altogether.

\PAR{Reliable broadcast.}{Algorithm~\ref{algo:reliablebroadcast} shows the
  instructions of reliable broadcast. Even in presence of message duplicates it
  avoids multiple deliveries of a same message. To achieve this, the most
  straightforward structure is a set saving all new received messages. However,
  it increases linearly with the number of delivered messages (\REF). Assigning
  a unique identifier $\langle p,\, counter \rangle$ to each message changes the
  complexity. It becomes a vector that increases linearly with the number of
  processes that ever broadcast a message~\cite{fidge1988timestamps}. Using
  interval tree clocks~\cite{almeida2008interval} slightly overloads messages
  with identifiers but it improves the space complexity: the local structure
  increases linearly with the number of processes that are currently involved in
  broadcasting.}


% \TODO{Rework.} Represented in Algorithms~\ref{algo:fifobroadcast}
% and~\ref{algo:bufferbroadcast} by Function $alreadyReceived$. Causal ordering
% and detecting duplicated receipts are orthogonal problems. In this paper, we do
% not provide an implementation for the later. The simplest approach consists in
% saving all received messages (\REF). However, the size of this set linearly and
% monotonically increases as the number of broadcast messages increases. One would
% prefer an approach based on vectors where one entry corresponds to the number of
% messages received by a particular process~\cite{fidge1988timestamps}. Such
% approach do not require to piggyback additional data in the message. However, it
% requires to store locally a vector the size of which increases linearly compared
% to the number of processes that ever broadcast a message. Interval tree
% clocks~\cite{almeida2008interval} allow processes to reduce this complexity. It
% becomes linear in terms of number of processes that are currently involved in
% broadcasting. Possible improvements could take advantage of the fact that the
% number of duplicates is equal to the number of incoming links. However, it does
% not hold in dynamic networks where additional links are established. Finding a
% sublinear bound for detecting duplicated receipts remains an open problem.


\PAR{Overlay network.}{Values such as the number of messages sent by each
  process, or the number of hops for a message to reach all processes, are
  interdependent values brought by the overlay network. For instance, random
  peer-sampling protocols~\cite{jelasity2007gossip} build network overlays with
  properties similar to those of random graphs~\cite{erdos1959random}. They
  provide each process with a random subset of neighbors the size of which is
  logarithmically scaling with the network size. The number of messages sent by
  each process for each broadcast message is logarithmic.  Since random
  peer-sampling protocols build topologies close to random graphs, messages take
  a logarithmic number of hops to reach all processes. In addition, random
  peer-sampling protocols such as \SPRAY~\cite{nedelec2017adaptive} or
  \CYCLON~\cite{voulgaris2005cyclon} create links using only
  neighbor-to-neighbor interactions, i.e., they establish links only two hops
  apart. It takes only 4 hops for new links to get acknowledged.  The overhead
  brought by these messages is negligible. The acknowledgment time of buffers,
  hence the size of buffers, remains small.}

The next section shows an experiment that highlights the influence of
\CBROADCAST's way to ensure causal order on the underlying overlay network.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../paper"
%%% End:
