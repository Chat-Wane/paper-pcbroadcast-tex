
\section{Issues and motivations}
\label{sec:motivations}

\begin{figure}
  \begin{center}
  \input{./input/figgeneralproblem.tex}
  \caption{\label{fig:generalproblem}Broadcast without causal order
    enforcement.}
  \end{center}
\end{figure}


% \TODO{Bla bla bla intuition is to avoid the following example. It becomes
%   obvious if $m$ is insertion and $m'$ is removal.}

Broadcast protocols ensure that all connected processes receive and deliver each
broadcast message~\cite{hadzilacos1994modular}. Applications often require more
guarantees on message delivery to ensure consistency criteria (\REF). For
instance, conflict-free replicated data types~\cite{shapiro2011comprehensive}
are replicated data structures ensuring eventual
consistency~\cite{bailis2013eventual}. Replicas eventually converge to an
identical state. CRDTs for sets~\cite{mukund2014optimized} and
sequences~\cite{weiss2009logoot} are extensively used in distributed data stores
such as Riak, Dynamo, or Cassandra (\REF) and distributed collaborative editors
such as Crate, or Peerpad (\REF). They feature basic operations such as
insertion and deletion that require causal order: the deletion of an element
must follow its insertion.

Figure~\ref{fig:generalproblem} illustrates the need of a mechanism ensuring
causal order in message deliveries. Process $p_1$ broadcasts and delivers
$m$. Process $p_2$ receives and delivers $m$. Then, it broadcasts and delivers
$m'$. Process $p_3$ receives $m'$ before $m$. Without any causal order
enforcement, $p_3$ delivers $m'$ before $m$ violating the condition stating that
the delivery of $m$ should precede the delivery of $m'$.

In this example, if each process hosts the replica of a set. Process $p_1$
inserts the element $a$ in the set and broadcasts the operation in $m$. Process
$p_2$ receives the operation and integrates $a$ to its own copy. Then, Process
$p_2$ removes $a$ from its set and broadcast the operation in $m'$. Process
$p_3$ receives $m'$ stating that $a$ should be removed. Since it does not have
$a$ in its replica, it does nothing. When it receives $m$ it adds $a$ to its
replica. Copies are divergent, for $p_1$ and $p_2$ ends up empty while $p_3$ has
$a$. It breaks eventual consistency.

Causal broadcast ensures causal order on message deliveries. Consequently, it
releases applications from the burden of tracking causal relationship between
operations. However, causality tracking has proven expensive in large and
dynamic networks (\REF).

\begin{table}
  \caption{\label{table:comparison} Space and time complexity of causal broadcast protocols. $N$ is the number of processes. $W$ is the number of messages received but waiting to be delivered.
    $P$ is the number of messages that are not yet purged.
    $B$ is the size of a set of temporary buffers.}
  \input{input/tableoverlayvstimestamp.tex}
\end{table}

% We distinguish two families of causal broadcast. Reactive approaches check at
% each receipt if the delivery of the message would violate causal order. In such
% case, they delay the delivery until preceding messages arrive. Preventive
% approaches make sure that messages are always ready to be delivered when a
% process receives it.  Table~\ref{table:comparison} highlights the limitations of
% state-of-the-art reactive and preventive approaches. It states our objective and
% it positions our approach towards state-of-the-art.

% \subsection{Reactive approaches}

First row of Table~\ref{table:comparison} shows the complexity of a
vector-clock-based representative~\cite{schwarz1994detecting} of reactive
approaches. % Most state-of-the-art approaches are
% reactive~\cite{almeida2008interval,fidge1988timestamps,hadzilacos1993fault,mattern1989virtual,mostefaoui2017probabilistic,singhal1992efficient}. 
Each broadcast message conveys control information the size of which increases
linearly with the number of processes. Each process must check at each receipt
if the message is ready for causal delivery which takes linear time in terms of
number of processes and number of messages delayed. Consequently, even if its
operation works in dynamic networks where membership changes over time, it
eventually becomes expensive and inefficient.

% , and links can be added or removed at any time.

% \PAR{Message overhead.}{The size of these control information increases linearly
%   with either the number of messages~\cite{hadzilacos1993fault} or the number of
%   processes that ever broadcast a
%   message~\cite{almeida2008interval,fidge1988timestamps,mattern1989virtual,mostefaoui2017probabilistic,singhal1992efficient}. These
%   approaches do not handle large networks. These approaches eventually become
%   impracticable in dynamic networks, for processes claim an entry when they join
%   that cannot be safely reclaimed when they leave.}

% \PAR{Local space.}{Control information becomes useful to check if a message is
%   ready to be delivered, i.e., messages that should be delivered beforehand are
%   actually delivered. Each process locally maintains a vector representing the
%   current state of delivery ($O(N)$).  In case the message is not ready, it goes
%   into a buffer along with its control information ($O(W.N)$).}

% \PAR{Delivery time.}{Upon each receipt, a process must check again all waiting
%   messages $W$. A message is ready if only 1 entry among all $N$ entries is
%   incremented. It requires $O(N)$ steps, hence $O(W.N)$ for the whole
%   buffer. Applications where efficiency is an important matter (\REF) cannot use
%   these approaches, for they slow down over time.}


% \begin{figure}
%   \begin{center}
%     \input{input/figvector.tex}
%     \caption{\label{fig:vector}Causal broadcast using vector clocks.}
%   \end{center}
% \end{figure}


% \EXAMPLE{Example of vector clock-based causal
%   broadcast.}{Figure~\ref{fig:vector} shows a broadcast protocol that ensures
%   causal delivery by using vector clocks. When Process $p_1$ broadcasts its
%   message $m$, it increments its entry in its vector clock and overloads the
%   message with it: $m_{1,\,0,\,0}$. When Process $p_2$ receives the message, it
%   checks if it is ready. It immediately delivers it, for the received vector is
%   only 1 increment away from its own vector clock. Then Process $p_2$ broadcasts
%   a message $m'$. It increments its own entry and overloads the message with its
%   vector $[1,\,1,\,0]$. This acknowledges that the delivery of $m$ precedes the
%   broadcast of $m'$. When Process $p_3$ receives the later, it detects that $m'$
%   is not ready and delays it until it receives and delivers $m$. Then, $p_3$
%   checks $m'$ again. $p_3$ finds that $m'$ is ready and delivers it. Using
%   vector clocks, the message delivery order follows causal order.}


% \TODO{Conclusion?}


% \subsection{Preventive approaches}

On the opposite, second row of Table~\ref{table:comparison} shows the complexity
of a preventive approach~\cite{friedman2004causal}. It outperforms the reactive
approach: message overhead is constant; it safely prunes the local structure;
message delivery time is constant. \TODO{How, and why it works.}

\begin{figure}
  \begin{center}
    \input{./input/figstatic.tex}
    \caption{\label{fig:static}Preventive broadcast in static networks.}
  \end{center}
\end{figure}

\EXAMPLE{Example of preventive broadcast in static
  network.}{Figure~\ref{fig:static} shows a broadcast protocol that ensures
  causal delivery by using FIFO channels.  The network is static and comprises 3
  processes $p_1$, $p_2$, $p_3$ linked to each other. The figure does not show
  messages forwarded by $p_3$ for the sake of clarity.  The processes receive
  $m$ and $m'$ multiple times but there exists no link in the paths from $p_2$
  to $p_3$ that carries $m'$ without having carried $m$ beforehand. Hence, the
  delivery of $m$ always precedes the delivery of $m'$ at any process.}


However, this only holds for static networks where membership remains unchanged,
and processes cannot add nor remove communication links. As soon as a process
adds a communication link to another process, causal delivery may be violated. 

% \PAR{Message overhead.}{This approach relies on FIFO links. Each message must
%   convey only 1 scalar to implement FIFO. Since processes must deliver each
%   message exactly once, each message also convey a unique identifier, e.g.,
%   $\langle process\_id,\, increasing\_counter\rangle$. Hence, $O(1)$.}

% \PAR{Local space.}{Since the network is static, each process knows the number of
%   copies it must receive. It can prune its local structure when it receives the
%   expected number of copies. We cannot achieve better local space complexity.}

% \PAR{Delivery time.}{Received messages are ready when they arrive. Processes
%   only check if the received message is a copy of an already delivered
%   message. It achieves this in constant time.}


\begin{figure}
  \begin{center}
    \input{./input/figproblem.tex}
    \caption{\label{fig:problem}Preventive broadcast in dynamic network.}
  \end{center}
\end{figure}

\EXAMPLE{Example of preventive approach in dynamic network.}{
  Figure~\ref{fig:problem} illustrates the issue with the establishment of new
  FIFO channels. In this example, a FIFO channel links $p_1$ to $p_2$; another
  links $p_2$ to $p_3$; none links $p_1$ to $p_3$. Other FIFO channels may exist
  but we do not show them for the sake of simplicity. Process $p_1$ broadcasts
  $m$ and delivers it. $p_3$ receives it by the intermediary of $p_2$. In the
  meantime, $p_1$ creates a FIFO channel to $p_3$, then broadcasts $m'$ to $p_2$
  and $p_3$. Since the path through $p_2$ is longer in terms of propagation time
  compared to the direct connections from $p_1$ to $p_3$, Process $p_3$ receives
  and delivers $m'$ before $m$. It violates causal order, for $m'$ precedes $m$.
}

% \subsection{Objective}

% Third row of Table~\ref{table:comparison} shows our objective. We want to
% outperform reactive approaches by using the preventive principle extended to
% dynamic networks. To handle large and dynamic networks, our protocol must
% overload messages with control information sublinearly increasing with the
% network size. We expect delivery time to reflect this complexity change by
% becoming sublinear too. We expect local space complexity to be at least linearly
% increasing with the number of processes, for no approach does better in dynamic
% networks.

Last row of Table~\ref{table:comparison} shows the complexity we achieve with
our causal broadcast. Similarly to the preventive approach, complexity stays
constant in terms of message overhead and delivery time. The local space
complexity is linear in terms of number of processes. \TODO{We expect this to be
  the minimum in dynamic settings.} In addition, our algorithm employs another
local structure to ensure causal order but we show that we can bound it in
Algorithm~\ref{algo:boundingbuffer}.



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../paper"
%%% End:
